{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Gaussian Mixture Models with RPCircuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RPCircuits, Random, Distributions\n",
    "\n",
    "Random.seed!(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a gaussian with `mean = 0.3` and `variance = 1.0` using the `Distributions` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureModel{Normal}(K = 3)\n",
       "components[1] (prior = 0.2000): Normal{Float64}(μ=-2.0, σ=1.2)\n",
       "components[2] (prior = 0.5000): Normal{Float64}(μ=0.0, σ=1.0)\n",
       "components[3] (prior = 0.3000): Normal{Float64}(μ=3.0, σ=2.5)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm = MixtureModel(Normal[\n",
    "   Normal(-2.0, 1.2),\n",
    "   Normal(0.0, 1.0),\n",
    "   Normal(3.0, 2.5)], [0.2, 0.5, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate a dataset `D` with `N` samples of the previous distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000×1 Matrix{Float64}:\n",
       " -0.873793482209626\n",
       "  2.818545329885325\n",
       "  1.4386832757114134\n",
       " -1.175371133217587\n",
       "  0.9523284631212727\n",
       " -2.4491221222621453\n",
       "  0.20092508863895137\n",
       " -1.5308390628427373\n",
       "  0.6489473612718025\n",
       "  0.4860050240607374\n",
       " -2.247935737377431\n",
       "  0.10477079178892111\n",
       "  1.3110173557334994\n",
       "  ⋮\n",
       "  0.8594637451805943\n",
       "  1.3584033067137333\n",
       "  0.7605620037727235\n",
       " -1.2762137902064086\n",
       "  2.679433979161\n",
       " -1.3598523470083919\n",
       "  5.188015849234176\n",
       "  4.3694021361772934\n",
       "  4.6825452918826915\n",
       " -0.544051909308209\n",
       " -2.169728584197887\n",
       " -0.3504598914029526"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100_000\n",
    "\n",
    "samples = rand(gmm, N)\n",
    "\n",
    "D = reshape(samples, length(samples), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `RPCircuits`, we create a `Gaussian Node` `G` with the same `mean` and `variance` as the previous gaussian distribution. Then, we apply the `NLL` function to see the Negative Log-Likelihood of `G` w.r.t. `D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model NLL = 2.2722570690152324\n"
     ]
    }
   ],
   "source": [
    "G1, G2, G3 = Gaussian(1, -2.0, 1.2), Gaussian(1, 0.0, 1.0), Gaussian(1, 3.0, 2.5)\n",
    "S = Sum([G1, G2, G3], [0.2, 0.5, 0.3])\n",
    "println(\"Original model NLL = \", NLL(S, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an arbitraty `Gaussian Node`that has both `mean` and `variance` different from the distribution `gauss`. Then, we apply the `EM` algorithm to learn a better distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM initial NLL = 3.3272542282069226\n",
      "EM final NLL = 2.2201693104383793\n",
      "Sem = + 1 0.3336793753362203 2 0.3477707524950897 3 0.31854987216868996\n",
      "G1em = gaussian 1 -1.34337243854077 1.9032462644722008\n",
      "G2em = gaussian 1 0.14718316991449149 0.8082957002863795\n",
      "G3em = gaussian 1 2.8565047848037755 6.603907557624629\n"
     ]
    }
   ],
   "source": [
    "G1em, G2em, G3em = Gaussian(1, -1.0, 1.0), Gaussian(1, 0.0, 1.0), Gaussian(1, 1.0, 1.0)\n",
    "Sem = Sum([G1em, G2em, G3em], [1/3, 1/3, 1/3])\n",
    "\n",
    "Lem = SEM(Sem; gauss=true)\n",
    "\n",
    "println(\"EM initial NLL = \", NLL(Sem, D))\n",
    "\n",
    "for i = 1:50\n",
    "    update(Lem, D; learngaussians=true, verbose=false)\n",
    "end\n",
    "\n",
    "println(\"EM final NLL = \", NLL(Sem, D))\n",
    "\n",
    "println(\"Sem = $Sem\")\n",
    "println(\"G1em = $G1em\")\n",
    "println(\"G2em = $G2em\")\n",
    "println(\"G3em = $G3em\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the example above, we create a `Gaussian Node` with both `mean` and `variance` differente from the distribution `gauss`. However, we apply the `Gradient Descent` algorithm in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1grad, G2grad, G3grad = Gaussian(1, -1.0, 1.0), Gaussian(1, 0.0, 1.0), Gaussian(1, 1.0, 1.0)\n",
    "# Incialize weigths close to zero\n",
    "w = rand(truncated(Normal(0, 0.1), 0.1, Inf), 3)\n",
    "Sgrad = Sum([G1grad, G2grad, G3grad], w)\n",
    "\n",
    "Lgrad = Gradient(Sgrad, gauss=true)\n",
    "\n",
    "println(\"Grad initial NLL = \", NLL(Sgrad, D))\n",
    "\n",
    "for i = 1:1_000\n",
    "    update(Lgrad, D; learningrate=0.01, learngaussians=true, verbose=false)\n",
    "end\n",
    "\n",
    "#norm_V = Vector{Float64}(undef, length(Sgrad))\n",
    "# TODO remover isso e normalizar circuito\n",
    "#norm_const = RPCircuits.log_norm_const!(norm_V,Lgrad.circ.C)\n",
    "\n",
    "RPCircuits.normalize_circuit!(Sgrad; gauss=true)\n",
    "\n",
    "println(\"Grad final NLL = \", NLL(Sgrad, D))\n",
    "println(\"Sgrad = $Sgrad\")\n",
    "println(\"G1grad = $G1grad\")\n",
    "println(\"G2grad = $G2grad\")\n",
    "println(\"G3grad = $G3grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = quantile.(gauss, [0.01, 0.99])\n",
    "d = Normal(params[1][1], params[1][2])\n",
    "min, max = quantile.(d, [0.01, 0.99])\n",
    "if lo < min min = lo end\n",
    "if hi > max max = hi end\n",
    "x = range(min, max; length = 1_000)\n",
    "@pgf Axis(Plot({thick, blue }, Table(x, pdf.(d, x))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
