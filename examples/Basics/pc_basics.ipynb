{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple PC with RPCircuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/code/RPCircuits.jl`\n",
      "┌ Info: Precompiling RPCircuits [a494de23-34c1-4aeb-b541-d9435dced8c8]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/home/jonasrlg/code/RPCircuits.jl/\")\n",
    "using RPCircuits, Random\n",
    "using Distributions: rand, truncated, Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easyest way to build a PCs with RPCircuits uses a bottom-up strategy, definin first the `leaf` nodes, then `product` nodes, and lastly `sum` nodes. \n",
    "\n",
    "As an example, we start building a simple Circuit with 8 indicator (leafs), 4 products and 1 sum node.\n",
    "\n",
    "![basic](pc_example_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have the foundation of the PC, the **leaf** nodes. In this case the variables **a**, **b** and their respective negations **na** and **nb**. To declare an indicator leaf node using RPCircuits, we call the function `Indicator()`, that needs **two** arguments. The first argument simply refers to the variable's `scope` (the indices of the variables associated with the Indicator node). The second argument, corresponds to the `value` such that the Indicator node outputs `true` (if `value = 1.0`, the Indicator node outputs `true` only when its input is `1.0`). Using the packag we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(indicator 1 1.0, indicator 1 0.0, indicator 2 1.0, indicator 2 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, na, b, nb = Indicator(1, 1.0), Indicator(1, 0.), Indicator(2, 1.), Indicator(2, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the second layer with 4 **product** nodes. To define a product `P`, we only need to call the function `Product(v)`, where `v`  is the vector containing all children of `P`. Hence, we can build the four products of our PC by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(* 1 2, * 1 2, * 1 2, * 1 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1, P2, P3, P4 = Product([a,b]), Product([a,nb]), Product([na,b]), Product([na,nb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we have the **sum** node. To define a sum  node `S`, we have to call the function `Sum(v, w)`, where `v` is the vector of children of `S`; and `w` is the vector of corresponding weights. This can easily be done by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circuit with 9 nodes (1 sum, 4 products, 4 leaves) and 2 variables:\n",
       "  1 : + 1 0.4 2 0.3 3 0.2 4 0.1\n",
       "  2 : * 1 2\n",
       "  3 : * 1 2\n",
       "  4 : indicator 1 0.0\n",
       "  5 : * 1 2\n",
       "  6 : indicator 2 0.0\n",
       "  7 : * 1 2\n",
       "  8 : indicator 2 1.0\n",
       "  9 : indicator 1 1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = Sum([P1, P2, P3, P4], [0.4, 0.3, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have the circuit\n",
    "![basic](spn_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the `scope` of a circuit rooted at a node `C`, we can type `scope(C)`. Therefore, the scope of our circuit is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitSet with 2 elements:\n",
       "  1\n",
       "  2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manul marginalization: 0.10000000000000002 + 0.2\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "println(\"Manul marginalization: \", S(x,0), \" + \", S(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: incomplete: premature end of input",
     "output_type": "error",
     "traceback": [
      "syntax: incomplete: premature end of input",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "println(\"Marginalization using inference: \", marginalize(S,[x],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manul marginalization: 0.2 + 0.4\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "println(\"Manul marginalization: \", S(0,y), \" + \", S(1,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: incomplete: premature end of input",
     "output_type": "error",
     "traceback": [
      "syntax: incomplete: premature end of input",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[9]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "println(\"Marginalization using inference: \", marginalize(S,[y],[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RPCircuits, it is possible to randomly sample complete configurations of the variables associated with a circuit `C`. We can do this using the function `rand(C)`, that creates a sample according to the probability defined by the PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = rand(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a positive integer `N` to `rand(C, N)`, creates `N` random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Matrix{Float64}:\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " ⋮    \n",
       " 1.0  1.0\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       " 0.0  0.0\n",
       " 1.0  1.0\n",
       " 0.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 0.0  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(42)\n",
    "N = 1_000\n",
    "D = rand(S, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function `NLL(S, D)`, we have the `Negative Log-Likelihood` of the PC `S` w.r.t the dataset `D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model NLL = 1.2905776805822853\n"
     ]
    }
   ],
   "source": [
    "println(\"Original model NLL = \", NLL(S, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have an initial circuit `Sem = Sum([P1, P2, P3, P4], [0.25, 0.25, 0.25, 0.25])` and we want to learn the function `S` (such that configurations `(a,b)`, `(a,nb)`, `(na,b)` and `(na, nb)` have respective probabilities `0.4`, `0.3`, `0.2` and `0.1`). Firstly, we can check the initial `NLL` of our model `Sem` in relation to the dataset `D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NLL = 1.3862943611198644\n"
     ]
    }
   ],
   "source": [
    "Sem = Sum([P1, P2, P3, P4], [0.25, 0.25, 0.25, 0.25])\n",
    "println(\"Initial NLL = \", NLL(Sem, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pass both our circuit `Sem` and the dataset `D` as an input to the `EM` algorithm (Expectation-Maximization algorithm, more to know about it [here][murphy]). To do this, we first define the learner `L = SEM(S)`. Then, we have `m` calls of the `update` function, for `m` iterations of the `EM` algorithm.\n",
    "\n",
    "[murphy]: https://probml.github.io/pml-book/book1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lem = SEM(Sem)\n",
    "\n",
    "for i = 1:50\n",
    "    update(Lem, D)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 adjoint(::Vector{Float64}) with eltype Float64:\n",
       " 0.381987  0.317993  0.192006  0.108014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sem.weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we can apply the `NLL` function another time, to see the improvement obtained by the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final NLL = 1.2891629841331282\n"
     ]
    }
   ],
   "source": [
    "println(\"Final NLL = \", NLL(Sem, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the Gradient Descent algorithm (more to know about it [here][murphy]) to learn a circuit `Sgrad` w.r.t the dataset `D`. In this process, we have a sligthly different approach, because we initalize the sum-weights near zero (more to know about it [here][trapp]).\n",
    "\n",
    "[murphy]: https://probml.github.io/pml-book/book1.html\n",
    "[trapp]: https://arxiv.org/abs/1905.08196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0.0007883556016042918, 0.0006316208311167526, 0.0014386832757114134, 0.000796126919278033]"
     ]
    }
   ],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "# Incialize weigths close to zero\n",
    "w = rand(truncated(Normal(0, 0.001), 0, Inf), 4)\n",
    "print(\"w = $w\")\n",
    "\n",
    "Sgrad = Sum([P1, P2, P3, P4], w)\n",
    "\n",
    "# ';' hides output\n",
    "Lgrad = Gradient(Sgrad);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the circuit `Sgrad` is not normalized, we need to compute its **normalizing constant**. We do this by using the function `log_norm_const` that outputs the `log` of the normalizing constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.6117175656758524"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing Constant of the circuit0\n",
    "norm_const = log_norm_const(Sgrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is possible to obtain the real `NLL` of `Sgrad` w.r.t `D` by adding `norm_const` to `NLL(Sgrad, D)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NLL = 1.48777761083484\n"
     ]
    }
   ],
   "source": [
    "println(\"Initial NLL = \", NLL(Sgrad, D) + norm_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can apply the Gradient Descent algorithm to `Sgrad` w.r.t `D` and then see the improvement obtained by the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 1.4877776108347467\n",
      "Score = 1.3263978422853493\n",
      "Score = 1.3263156856948672\n",
      "Score = 1.326233690041726\n",
      "Score = 1.3261518549872733\n",
      "Score = 1.3260701801943475\n",
      "Score = 1.3259886653272566\n",
      "Score = 1.3259073100517744\n",
      "Score = 1.3258261140351324\n",
      "Score = 1.3257450769460193\n",
      "Score = 1.3256641984545592\n",
      "Score = 1.3255834782323168\n",
      "Score = 1.325502915952283\n",
      "Score = 1.3254225112888667\n",
      "Score = 1.3253422639178938\n",
      "Score = 1.3252621735165913\n",
      "Score = 1.3251822397635866\n",
      "Score = 1.3251024623388952\n",
      "Score = 1.3250228409239158\n",
      "Score = 1.3249433752014241\n",
      "Score = 1.3248640648555634\n",
      "Score = 1.3247849095718394\n",
      "Score = 1.3247059090371067\n",
      "Score = 1.3246270629395753\n",
      "Score = 1.3245483709687853\n",
      "Score = 1.3244698328156173\n",
      "Score = 1.3243914481722743\n",
      "Score = 1.3243132167322778\n",
      "Score = 1.3242351381904616\n",
      "Score = 1.324157212242964\n",
      "Score = 1.324079438587223\n",
      "Score = 1.3240018169219665\n",
      "Score = 1.3239243469472102\n",
      "Score = 1.3238470283642418\n",
      "Score = 1.3237698608756245\n",
      "Score = 1.3236928441851916\n",
      "Score = 1.3236159779980192\n",
      "Score = 1.3235392620204525\n",
      "Score = 1.3234626959600715\n",
      "Score = 1.323386279525697\n",
      "Score = 1.3233100124273827\n",
      "Score = 1.3232338943764115\n",
      "Score = 1.323157925085279\n",
      "Score = 1.3230821042677006\n",
      "Score = 1.3230064316385974\n",
      "Score = 1.3229309069140898\n",
      "Score = 1.3228555298114926\n",
      "Score = 1.3227803000493128\n",
      "Score = 1.322705217347239\n",
      "Score = 1.3226302814261313\n"
     ]
    }
   ],
   "source": [
    "for i = 1:50\n",
    "    update(Lgrad, D; learningrate=0.01)\n",
    "    println(\"Score = \", Lgrad.score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 adjoint(::Vector{Float64}) with eltype Float64:\n",
       " 4.69507  4.86952  1.3493  1.34121"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sgrad.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_circuit!(Sgrad) # Normalizing of circuit weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 adjoint(::Vector{Float64}) with eltype Float64:\n",
       " 0.383112  0.397347  0.110101  0.109441"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sgrad.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final NLL = 1.3225554920080314\n"
     ]
    }
   ],
   "source": [
    "println(\"Final NLL = \", NLL(Sgrad, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.2",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
